{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat6 = pd.read_csv('dat6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# an example data of a user (id = 2)\n",
    "i = 2\n",
    "data = dat6.loc[dat6.newid == i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MFU(data):\n",
    "    \n",
    "    from random import sample, seed\n",
    "    \n",
    "    # 1. Prepare train and test datasets\n",
    "    \n",
    "    data1 = data.sort_values('startTimeMillis')\n",
    "    data1.date = data1.date.astype(int)\n",
    "    \n",
    "    data2 = data1.groupby('ids').count()\n",
    "    data2.reset_index(level = 0, inplace = True)\n",
    "    \n",
    "    ses2 = data2.loc[data2.startTime > 1,:]\n",
    "    \n",
    "    ses2_list = list(ses2.ids.unique())\n",
    "    \n",
    "    data2s = data1.loc[data1.ids.isin(ses2_list)]\n",
    "    \n",
    "    list_apps = list(data2s.app_name.unique())\n",
    "    \n",
    "    ### Cross validation k = 5\n",
    "    \n",
    "    n = len(data2s.ids.unique()) # number of sessions\n",
    "    k = 5\n",
    "    m = n//k\n",
    "    set_sessions = set(ses2_list)\n",
    "    \n",
    "    train = []\n",
    "    test = []\n",
    "    left = set_sessions.copy()\n",
    "    \n",
    "    for i in range(5):\n",
    "        if i < 4:\n",
    "            seed(123)\n",
    "            tst = set(sample(left, m))\n",
    "            trn = set_sessions - tst\n",
    "\n",
    "            train_data = data2s.loc[data2s.ids.isin(trn)]\n",
    "            test_data = data2s.loc[data2s.ids.isin(tst)]\n",
    "\n",
    "            train.append(train_data)\n",
    "            test.append(test_data)\n",
    "\n",
    "            left -= tst\n",
    "        else:\n",
    "            tst = left\n",
    "            trn = set_sessions - tst\n",
    "\n",
    "            train_data = data2s.loc[data2s.ids.isin(trn)]\n",
    "            test_data = data2s.loc[data2s.ids.isin(tst)]\n",
    "\n",
    "            train.append(train_data)\n",
    "            test.append(test_data)\n",
    "\n",
    "            \n",
    "    # 2. Functions needed \n",
    "    \n",
    "    # function count the walks from this to that in the list_walks\n",
    "    def count_walks(this, that, list_walks):\n",
    "        r = 0\n",
    "        for walks in list_walks:\n",
    "            n = len(walks)\n",
    "            for i in range(n-1):           \n",
    "                if (walks[i] == this) & (walks[i+1] == that):\n",
    "                    r +=1\n",
    "        return r\n",
    "\n",
    "\n",
    "    # function predict the next app with the highest counting\n",
    "    def next_apps(data_train, napps):\n",
    "\n",
    "        dt = data_train.groupby('app_name').count().sort_values('ids', ascending=False)\n",
    "        dt.reset_index(level = 0, inplace = True)\n",
    "        \n",
    "        if len(dt) == 0:\n",
    "            return []   \n",
    "        elif len(dt) == 1:\n",
    "            result = [dt.iloc[0,0]]\n",
    "        elif len(dt) == 2:\n",
    "            result = list(dt.iloc[:2,0])\n",
    "        elif len(dt) == 3:\n",
    "            result = list(dt.iloc[:3,0])\n",
    "        elif len(dt) == 4:\n",
    "            result = list(dt.iloc[:4,0])\n",
    "        else:\n",
    "            result = list(dt.iloc[:5,0])\n",
    "\n",
    "        ind = min(napps, len(result))\n",
    "\n",
    "        return result[:ind]\n",
    "\n",
    "    def hit_rate_result(data_test, next_app_mostFrq):\n",
    "        ses_list_test = list(data_test.ids.unique())\n",
    "\n",
    "        list_walks_test = [] # keep the list of walks \n",
    "        for s in ses_list_test:\n",
    "\n",
    "            d = data_test.loc[data_test['ids'] == s,]\n",
    "            list_walks_test.append(list(d['app_name'])) \n",
    "\n",
    "        total, hit = 0, 0\n",
    "\n",
    "        for walks in list_walks_test:      \n",
    "            total += len(walks) - 1     \n",
    "            for walk in walks[1:]: \n",
    "                if walk in next_app_mostFrq:\n",
    "                    hit += 1\n",
    "\n",
    "        return round(hit/total, 4)\n",
    "\n",
    "    \n",
    "    # 3. Prediction Accuracy\n",
    "    \n",
    "    total_hit_rate = [0, 0, 0, 0, 0] # to keep the accuracy of LU1 model to predict number of apps\n",
    "    \n",
    "    for i in range(len(train)): \n",
    "        \n",
    "        data_train = train[i]\n",
    "        ses2_list = list(data_train.ids.unique())\n",
    "\n",
    "        list_walks = [] # keep the list of walks training\n",
    "        for s in ses2_list:\n",
    "\n",
    "            d = data_train.loc[data_train['ids'] == s,]\n",
    "            list_walks.append(list(d['app_name']))  \n",
    "\n",
    "        next_app_mostFrq = [next_apps(data_train, napps) for napps in range(1,6)]\n",
    "\n",
    "        data_test = test[i]\n",
    "        \n",
    "        for z in range(5):\n",
    "            \n",
    "            total_hit_rate[z] += hit_rate_result(data_test, next_app_mostFrq[z])\n",
    "    \n",
    "    return [round(total_hit_rate[i] /len(train), 4) for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test with id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6533010005950928\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() \n",
    "\n",
    "accuracy = MFU(data)\n",
    "\n",
    "end = time.time() \n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3776, 0.5153, 0.6536, 0.6946, 0.7107]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run and Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time() \n",
    "\n",
    "columns = [ 'MFU1', 'MFU2', 'MFU3', 'MFU4', 'MFU5']\n",
    "Result = pd.DataFrame(index = range(1,2010), columns = columns)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "for i in range(1,2010):\n",
    "    data = dat6.loc[dat6.newid == i, :]\n",
    "    \n",
    "    accuracy = MFU(data)\n",
    "     \n",
    "    for j in range(5):\n",
    "        Result.iloc[i-1, j] = accuracy[j]\n",
    "\n",
    "Result.to_excel('MFU_2009.xlsx')\n",
    "\n",
    "end = time.time() \n",
    "print(end - start) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
